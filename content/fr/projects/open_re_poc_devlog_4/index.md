+++
author = 'Turbo Tartine'
date = '2025-08-28T08:43:37+02:00'
draft = true
title = "OpenRE devlog 4 : Fusion des mondes. Part I"
description = 'devlog 4 du projet OpenRE'
+++

[‚¨ÖÔ∏è Vers Pr√©c√©dent : "OpenRE devlog 3 : Harmonisation des normales"](projects/open_re_poc_devlog_3)

## I. Introduction
Gr√¢ce au travail effectu√© jusqu'ici, nous sommes en mesure de faire nos premiers rendus. Pour cela nous allons partir de la sc√®ne actuelle √† laquelle nous allons ajouter un peu de mouvement mais surtout, de la lumi√®re.

Comme d'habitude nous adopteront une aproche int√©rative. Nous commenceront par la version la plus rudimentaire possible que nous complexifieront petit √† petit jusqu'√† atteindre notre but. A la fin nous auront un rendu en temps r√©√®l coh√©rent comprenant :
- de la g√©om√©trie d√©terministe (pr√©-rendue dans Blender)
- de la g√©om√©trie int√©ractive (rendue en temps r√©√®l par Godot)
- de la lumi√®re d√©terministe (affectant aussi la g√©om√©trie int√©ractive)
- de la lumi√®re int√©ractive (affectant aussi la g√©om√©trie d√©terministe)

Ou du moins c'est ce que je pr√©voyais √† l'origine. Mais me suis rendu compte en cours de route que j'avais peut √™tre un peu sous estim√© le morceau. J'ai donc d√©cider de le couper en 2. Dans cette premi√®re partie, nous ne traiterons donc pas la lumi√®re d√©terministe, et seulement partiellement l'int√©ractive. Mais ce n'est que partie remise biensure.

## II. Pr√©paration de la sc√®ne
Jusqu'ici, nous avons cherch√© √† comparer des sc√®nes identiques dans le but d'√©taloner Godot et Blender afin qu'ils produisent des donn√©es bien harmonis√©es. Mais dans un usage normal, la g√©om√©trie du monde int√©ractif est bien entandu diff√©rente de celle du monde d√©terministe. Dans Godot, on va donc cacher les √©l√©ments de la sc√®ne pr√©c√©dement import√©e depuis Blender (qui sera notre sc√®ne d√©terministe).

<img alt="Capture du dock scene de Godot dans lequel tous les mesh issus de la simple-scene.blend ont √©t√© masqu√©s" src="./images/hide_det_scn.opti.webp" style="display: block; margin-left: auto; margin-right: auto;" /> 

On va ensuite ajouter de nouveaux meshes, et comme ces meshes font partie du monde int√©ractif, on ne se privera pas de les faire bouger.

[![Gif de l'editeur de godot montrant un agencement de primitives g√©om√©triques de couleurs unies qui tournent sure elle meme. Il y a un arceau qui ressemble √† la porte des √©toiles et un cube jaune au centre](images/int_geometry-anim.webp)](images/int_geometry-anim.webp)

Enfin, nous allons desactiver l'oracle et cr√©er un nouveau post-process `ore_compositor` qui sera charg√© de fusionner les 2 sc√®nes en temps r√©√®l. Comme l'oracle, il prendra en entr√©e les maps des G-Buffers d√©terministe et interactif. Mais il aura √©galement besoin de donn√©es supl√©mentaires relatives √† la sc√®ne : les propri√©t√©s de la cam√©ra active et plus tard des lumi√®res.

<img alt="Capture du dock Inspector de Godot dans lequel on peut voir les parametres du post-process ore_compositor" src="./images/ore_compositor.opti.webp" style="display: block; margin-left: auto; margin-right: auto;" /> 

On oubliera pas de desactiver le post-process quad de l'oracle et d'activer celui du compositor √† la place.

<img alt="Capture du dock scene de Godot dans lequel le post-process quad de l'oracle est masqu√© tandis que celui du ore_compositor est actif" src="./images/replace_oracle.opti.webp" style="display: block; margin-left: auto; margin-right: auto;" /> 

A pr√©sent voyons un peu de quoi est fait ce post-process.

## III. Composition de la G√©om√©trie
Dans cette premi√®re it√©rtation du shader de composition, nous allons laisser de c√¥t√© la lumi√®re pour nous concentrer sur la g√©om√©trie. L'objectif est d'avoir un premier rendu unlit d'une sc√®ne int√©ractive int√©gr√© √† une sc√®ne d√©terministe. Le tout biensure en respectant la profondeur, c'est √† dire que quelque soit le monde (int√©ractif ou d√©terministe), ce qui est devant est bien rendu par dessus ce qui est derri√®re.

Attention, pav√© en approche ! Voici le code complet de cette premi√®re version du shader :

```glsl
// USUAL GODOT POST-PROCESS STUFF
shader_type spatial;
render_mode unshaded, fog_disabled;

void vertex() {
	POSITION = vec4(VERTEX.xy, 1.0, 1.0);
}

// HELPER FUNCTIONS FROM THE ORACLE
#include "pre_process_utils.gdshaderinc"

// SCENE UNIFORMS
uniform float cam_near;
uniform float cam_far;

// INTERACTIVE G-BUFFER
uniform sampler2D i_depth_map : filter_nearest;
uniform sampler2D i_albedo_map : filter_nearest;

// DETERMINIST G-BUFFER
uniform sampler2D d_depth_map : filter_nearest;
uniform sampler2D d_diffuse_color_map : filter_nearest;

void fragment() {
	// SAMPLE G-BUFFERs
	vec3 i_depth_frag = texture(i_depth_map, SCREEN_UV).rgb;
	vec3 i_albedo_frag = texture(i_albedo_map, SCREEN_UV).rgb;
	
	vec3 d_depth_frag = texture(d_depth_map, SCREEN_UV).rgb;
	vec3 d_diffuse_color_frag = texture(d_diffuse_color_map, SCREEN_UV).rgb;
	
	// DATA HARMONIZATION
	i_depth_frag = pre_process_i_depth(i_depth_frag);
	d_depth_frag = pre_process_d_depth(d_depth_frag, cam_near, cam_far);
	
	// DATA SELECTION (according to depth)
	float depth_frag;
	vec3 albedo_frag;
	bool is_frag_interactive = d_depth_frag.r < i_depth_frag.r;
	if(is_frag_interactive) {
		depth_frag = i_depth_frag.r;
		albedo_frag = i_albedo_frag;
	}
	else {
		depth_frag = d_depth_frag.r;
		albedo_frag = d_diffuse_color_frag;
	}
	
	// FINAL FRAGMENT COLOR
	ALBEDO = albedo_frag.rgb;
}
```

Ne vous inqui√©tez pas, on va le disequer ensemble dans les sections suivantes.

### 1. Definition habituelle d'un post-process
On en a d√©j√† parl√©, ces premi√®res lignes sont les m√™me pour tous les post-process.

```glsl
// USUAL GODOT POST-PROCESS STUFF
shader_type spatial;
render_mode unshaded, fog_disabled;

void vertex() {
	POSITION = vec4(VERTEX.xy, 1.0, 1.0);
}
```

### 2. Include des helpers de l'oracle
```glsl  
// HELPER FUNCTIONS FROM THE ORACLE
#include "pre_process_utils.gdshaderinc"
```

Rappelez-vous, pour harmoniser les donn√©es, l'Oracle appliquait des pre-traitements √† certaines maps. J'ai extrait et regroup√©es ces fonctions dans le fichier `pre_process_utils.gdshaderinc` que nous incluons ici. De cette mani√®re si nous modifions ces pre-traitements ils resteront valides pour les 2 post-process. Voici son contenu :

```glsl
vec3 pre_process_i_depth(vec3 i_depth) {
	return i_depth;
}

vec3 pre_process_d_depth(vec3 d_depth, float near, float far) {
	float z = d_depth.r * (far - near) + near;
	float unlinearized_depth = (z * far - near * far) / (far - near);
	unlinearized_depth /= z;
	return vec3(1.0 - unlinearized_depth, 0.0, 0.0);
}

vec3 pre_process_i_normal(vec3 i_normal, mat4 inv_view_matrix) {
	i_normal = i_normal * 2.0 - 1.0;
	i_normal = (inv_view_matrix * vec4(i_normal, 0.0)).xyz;
	return i_normal;
}

vec3 pre_process_d_normal(vec3 d_normal) {
	d_normal = vec3(d_normal.x, d_normal.z, -d_normal.y);
	return d_normal;
}
```

### 3. Parm√®tres d'entr√©e
Comme √©voqu√© pr√©c√©dement, le post-process va prendre en entr√©e des `uniforms` correspondant aux deux G-Buffers, plus quelques param√®tres additionnels relatifs √† la sc√®ne.

```glsl
// SCENE UNIFORMS
uniform float cam_near;
uniform float cam_far;

// INTERACTIVE G-BUFFER
uniform sampler2D i_depth_map : filter_nearest;
uniform sampler2D i_albedo_map : filter_nearest;

// DETERMINIST G-BUFFER
uniform sampler2D d_depth_map : filter_nearest;
uniform sampler2D d_diffuse_color_map : filter_nearest;
```

Pour l'instant, on a besoin :
- des param√®tres near et far de la cam√©ra active
- des texture de depth et d'alb√©do issues des G-Buffers int√©ractif et d√©termniste

L'alb√©do d√©terministe est ici appel√© `d_diffuse_color_map` car c'est son nom dans la terminologie Blender. Mais il s'agit bien de la m√™me chose.

### 4. Echantillonage des G-Buffers
Chaque map est √©chantillon√©e pour r√©cup√©rer le fragment correspondant. Dans la foul√©e on applique les fameux pre-traitements.

```glsl
void fragment() {
	// SAMPLE G-BUFFERs
	vec3 i_depth_frag = texture(i_depth_map, SCREEN_UV).rgb;
	vec3 i_albedo_frag = texture(i_albedo_map, SCREEN_UV).rgb;
	
	vec3 d_depth_frag = texture(d_depth_map, SCREEN_UV).rgb;
	vec3 d_diffuse_color_frag = texture(d_diffuse_color_map, SCREEN_UV).rgb;
	
	// DATA HARMONIZATION
	i_depth_frag = pre_process_i_depth(i_depth_frag);
	d_depth_frag = pre_process_d_depth(d_depth_frag, cam_near, cam_far);
	
	...
}
```

### 5. Selection des fragment
Ensuite, on se base sur la valeur de la depth pour d√©terminer si le fragment courant appartien √† la sc√®ne int√©ractive ou d√©terministe. On en profite alors pour assigner les donn√©es g√©om√©triques correspondantes aux variable `depth_frag` et `albedo_frag` que l'on utilisera dans la suite du shader.

```glsl
void fragment() {
	...
	
	// DATA SELECTION (according to depth)
	float depth_frag;
	vec3 albedo_frag;
	bool is_frag_interactive = d_depth_frag.r < i_depth_frag.r;
	if(is_frag_interactive) {
		depth_frag = i_depth_frag.r;
		albedo_frag = i_albedo_frag;
	}
	else {
		depth_frag = d_depth_frag.r;
		albedo_frag = d_diffuse_color_frag;
	}
	
	...
}
```

### 6. Affichage du fragment final
```glsl
void fragment() {
	...
	
	// FINAL FRAGMENT COLOR
	ALBEDO = albedo_frag.rgb;
}
```

Bon d'accord. la "suite du shader" est pour l'instant un peu courte. On ne fait qu'afficher directement l'alb√©do du monde selectionn√©. On ne se sert m√™me pas de `depth_frag`. Mais ne vous inqui√©tez pas √ßa va venir. Pour l'heure je vous propose d'admirer ce magnifique chapa√Ø !

{{< rawhtml >}} 

<video width="100%" controls muted loop playsinline autoplay>
    <source src="videos/unlit_chapai.mp4" type="video/mp4">
    Your browser does not support the video tag.  
</video>

{{< /rawhtml >}}

Oui je sais c'est pas tr√®s impressionnant sans lumi√®re. Mais au moins on peut constater que la s√©lection du monde selon la profondeur est correcte. En effet, les parties du chapa√Ø qui se trouvent sous podium sont bien invisible tandis que le rest est correctement rendu par dessus l'arri√®re plan.

Mission accomplie ! Place √† la lumi√®re maintenant.

## IV. Un premier mod√®le d'illumination
Avant de nous attaquer √† de la "vrai" lumi√®re, nous allons utiliser un mod√®le d'illumination pas du tout homologu√© bas√© uniquement sur l'att√©nuation de l'intensit√© selon la distance. En particulier, ce mod√®le ignore l'orientation des surfaces. Ce n'est pas du tout photor√©aliste mais cela produit un rendu que je trouve tr√®s interessant et qui se marie tr√®s bien √† des DA stylis√©es.

J'ai d√©couvert cette technique dans un talk de Theresa Latzko que j'avais trouv√© tr√®s inspirant. Elle y d√©crit en d√©tail comment elle √† d√©fini la direction artistique et impl√©ment√© le rendu de son jeu "Days of the  Porcupine". Si cela vous interesse voici le lien : https://www.youtube.com/watch?v=RoqDqHdBI2Y

[![Extrait de la pr√©sentation "Art of the Porcupine" par Theresa Latzko. A gauche un vertex lighting classic. A droite le fameux distance-only lighting](images/days_of_porcupine.opti.webp)](images/days_of_porcupine.opti.webp)
*Extrait de la pr√©sentation "Art of the Porcupine" par Theresa Latzko. A gauche un vertex lighting classic. A droite le fameux distance-only lighting*

Nous n'irons pas aussi loin qu'elle car nous visons une DA plut√¥t r√©aliste. Mais lui emprunter cette id√©e nous permet de passer par une √©tape interm√©diaire un peu plus simple d'un point de vu tecnique. Ce qui nous laisse d'autant plus te temps pour bien d√©tailler chaque points. Et on va commencer tout dessuite par une petite parenth√®se au sujet de la "inverse square law".

### 1. Inverse Square law
La inverse square law est une loie qui s'applique √† diff√©rentes quantit√© physiques dont l'intensit√© lumineuse iradiant d'une source ponctuelle. Elle dit que "l'intensit√©e lumineuse en un point de l'espace est inversement proportionnel au carr√© de la distance qui s√©pare ce point de la source". Ou de mani√®re plus compacte : I = I0 / d¬≤ (avec I0 l'intensit√© de la source et d la distance)

Une fa√ßon de se repr√©senter cette relation, c'est de penser √† une sphere centr√©e sur la source lumineuse. Les photons iradient de la source lumineuse en ligne droite dans toutes les directions et entrent en collision avec la sphere. Ces collisions sont r√©parties de mani√®re uniforme sur toute la surface de la sphere. 

Imaginez maintenant que cette sphere grossi. Le nombre de photons qui entrent en collision avec elle est toujours le m√™me, car la quantit√© de lumi√®re √©mise par la source ne d√©pend pas de la sphere. En revanche, la surface √† √©clairer est maintenant plus grande. La quantit√©e de lumi√®re re√ßue au m¬≤ est donc plus faible.

[![Illustration de l'inverse square law](images/Inverse_square_law.opti.webp)](images/Inverse_square_law.opti.webp)

La d√©croisance de la concentration de photons sur notre sphere est donc directement reli√©e √† la croissance de sa surface. Et la surface d'une sphere est proportionnelle au carr√© de son rayon (S = 4œÄr¬≤).

Bref, c'est la loi qu'on va utiliser pour mod√©liser notre lumi√®re.

### 2. Impl√©mentation
Avant toute chose, nous devons ajouter une OmniLight √† la sc√®ne int√©ractive. Cette derni√®re se verra assigner un script qui modifie periodiquement sa couleur et son intensit√©, et qui la fait orbiter autour de notre... instalation d'art contemporain (de pi√®tre inspiration) ?

[![Gif de l'editeur de godot montrant une light orbitant autours du chapa√Ø](images/rotolight-anim.webp)](images/rotolight-anim.webp)

Pour faciliter la localisation de notre lumi√®re, elle sera materialis√©e par une petite sphere blanche. Ce n'est pas primodial pour le resultat final, mais c'est un petit artifice qui m'a pas mal aid√© √† d√©bugger.

Nous pouvons maintenant reprendre le shader pour qu'il impl√©mente le "distance-only lighting" d√©crit pr√©c√©dement. Pour vous donner un apper√ßu global, voici les modifications apport√©es :

```glsl
// USUAL GODOT POST-PROCESS CODE
// HELPER FUNCTIONS FROM THE ORACLE
// SCENE UNIFORMS
...
uniform int nb_plights;
uniform vec3 plight_position[8];
uniform vec3 plight_color[8];
uniform float plight_intensity[8];

// INTERACTIVE G-BUFFER
// DETERMINIST G-BUFFER
...

void fragment() {
	// SAMPLE G-BUFFERs
	// DATA HARMONIZATION
	...
	
	vec3 diffuse_contrib = vec3(0.0);
	vec3 specular_contrib = vec3(0.0);
	
	// DATA SELECTION (according to depth)
	// WORLD POSITION FROM DEPTH
	vec3 ndc = vec3((SCREEN_UV * 2.0) - 1.0, depth_frag);
	vec4 world = INV_VIEW_MATRIX * INV_PROJECTION_MATRIX * vec4(ndc, 1.0);
	world.xyz /= world.w;
	vec3 frag_position = world.xyz;
	
	// ACCUMULATE LIGHT CONTRIBUTIONS
	for(int i = 0; i < nb_plights; i++) {
		vec3 light_vec = plight_position[i] - frag_position;
		float d2 = length(light_vec);
		d2 = pow(d2, 2.0);
		float attenuation = 1.0 / d2;

		vec3 C = plight_color[i];
		float I = plight_intensity[i];
		diffuse_contrib += C * I * albedo_frag * attenuation;
		//specular_contrib += NOT IMPLEMENTED YET
	}
	
	// FINAL FRAGMENT COLOR
	ALBEDO = diffuse_contrib + specular_contrib;
}
```

Mais comme d'habitude, on va expliquer tout √ßa en douceur.

#### 1.1. Param√®tres des lumi√®res
D'abord on doit fournir √† notre post-process entr√©e les parametres de la lumi√®re. A savoir :
- sa position
- sa couleur
- son intensit√©

Pour l'instant il n'y a qu'une seule lumi√®re, mais on compte bein en ajouter d'autres un jour alors on va pr√©parer le terrain d√®s maintenant en d√©clarant des tableaux plut√¥t que des variables simples. 

```glsl
// SCENE UNIFORMS
uniform float cam_near;
uniform float cam_far;

uniform int nb_plights;
uniform vec3 plight_position[8];
uniform vec3 plight_color[8];
uniform float plight_intensity[8];
```

Une petite minute, pourquoi a-t-on besoin d'un entier et de 3 tableaux pour stoquer √ßa ? Ce ne serait pas plus partique d'utiliser un tableau dynamique de structures ?

Il faut savoir qu'en GLSL, les tableaux sont tr√®s limit√©s : leur taille doit √™tre connue √† la compilation, et sous le capot ils sont souvent g√©r√©s comme une succession de variables simples. C‚Äôest plus une commodit√© syntaxique qu‚Äôun v√©ritable type de donn√©es dynamique comme on en a l'habitude sur du code CPU. 

Le seul moyen d'impl√©menter des tableaux r√©√®lement dynamiques est d'utiliser un SSBO (Shader Storage Buffer Objects). Mais en `GDShader` (le langage de shading de Godot) ni les SSBO ni les structures ne sont support√©es. Raison pour laquelle on est bloqu√© avec 3 tableaux de taille fixe et un entier pour encoder leur taille effective.

#### 1.2. Calcule de la position du fragment
Ensuite, pour pouvoir calculer la distance entre la source de lumi√®re et le fragment, il faut connaitre la position de ce dernier. Nous connaissons sa profondeur `depth_frag` et Godot nous fournis sa position √† l'√©cran √† travers la variable `SCREEN_UV`. Nous pouvons en d√©duire sa coordon√©e en espace [NDC](d√©finir cet espace).

A partir de l√†, il suffit d'appliquer la serie de transformations inverse au pipeline normal pour passer du NDC au world space.

```glsl
	// WORLD POSITION FROM DEPTH
	vec3 ndc = vec3((SCREEN_UV * 2.0) - 1.0, depth_frag);
	vec4 world = INV_VIEW_MATRIX * INV_PROJECTION_MATRIX * vec4(ndc, 1.0);
	world.xyz /= world.w;
	vec3 frag_position = world.xyz;
```
Vous vous demandez peut-√™tre √† quoi sert la ligne `world.xyz /= world.w;`. Il va falloir me faire confiance sur ce coup, parce que je ne vais pas faire un cours de math sur les coordonn√©es homog√®nes. D‚Äôabord parce que ce serait tr√®s long et un peu aust√®re. Mais en toute honn√™tet√©, c‚Äôest surtout un sujet complexe que je ne ma√Ætrise pas totalement. (D‚Äôailleurs, si vous avez de bonnes ressources, n‚Äôh√©sitez pas √† les partager en commentaire !)

Sans rentrer dans les d√©tails, voici ce que j‚Äôen comprends : l‚Äôid√©e est de passer dans un espace de dimension sup√©rieure pour profiter de propri√©t√©s math√©matiques plus interessantes. En programations graphiques on est principalement interess√© par :
- L'existance de la PERSPECTIVE_MATRIX
- La possibilit√© de mod√©liser la translation comme une multiplication de matrices
- La posibilit√© de diff√©rentier une position d'une direction

C'est pourquoi les API graphiques fonctionnent dans cet espace plut√¥t que dans l‚Äôespace euclidien classique. Pour passer d‚Äôune coordonn√©e euclidienne √† une coordonn√©e homog√®ne, il suffit d‚Äôajouter une composante √©gale √† 1 pour une position, ou 0 pour une direction. Ainsi en 3D, le vecteur (x, y, z) devient (x, y, z, 1) ou (x, y, z, 0). 

Pour revenir d‚Äôune coordonn√©e homog√®ne √† une coordonn√©e euclidienne, on divise tous les composants par le dernier. Par exemple, (x, y, z, w) devient (x/w, y/w, z/w). C'est exactement de l√† que vient la ligne magique : `world.xyz /= world.w;`.

#### 1.3. Calcule de la lumi√®re
Pour obtenir la couleur final du fragment, nous allons parcourir notre tableau de lumi√®re et accumuler les contribution lumineuses de chacune d'elle. Dans la plupart des mod√®les d'illumination, chaque contribution est compos√©e d'une partie diffuse et d'une partie sp√©culaire.

La partie diffuse est la partie de la lumi√®re que la mati√®re disperce dans toutes les directions. C'est elle qui nous permet de percevoir la couleur de l'objet. La partie speculaire repr√©sente la partie qui est refl√©chie plus majoritairement dans une direction particuli√®re. C'est ce qui produit des reflets brillants. Un mirroir par exemple est une mati√®re completement sp√©culaire. Il renvoit la lumi√®re dans une direction bien pr√©cise et ne la diffuse pas comme le ferait une balle en caoutchouc.

Le resultat final est la somme des contributions diffuses et sp√©culaires accumul√©es.

```glsl
void fragment() {
	...
	
	vec3 diffuse_contrib = vec3(0.0);
	vec3 specular_contrib = vec3(0.0);
	
	...
	
	// ACCUMULATE LIGHT CONTRIBUTIONS
	for(int i = 0; i < nb_plights; i++) {
		vec3 light_vec = plight_position[i] - frag_position;
		float d2 = length(light_vec);
		d2 = pow(d2, 2.0);
		float attenuation = 1.0 / d2;

		vec3 C = plight_color[i];
		float I = plight_intensity[i];
		diffuse_contrib += C * I * albedo_frag * attenuation;
		//specular_contrib += NOT IMPLEMENTED YET
	}
	
	// FINAL FRAGMENT COLOR
	ALBEDO = diffuse_contrib + specular_contrib;
}
```

Comme vous pouvez le constater, notre mod√®le du pauvre fait l'impasse sur la sp√©culaire. On pourrait bricoler quelque chose "en dur" pour faire illusion, mais nos G-Buffers actuels ne contiennent pas encore les propri√©t√©s de la mati√®re n√©cessaire au calcule de la contribution sp√©culaire.

```glsl
		vec3 C = plight_color[i];
		float I = plight_intensity[i];
		diffuse_contrib += C * I * albedo_frag * attenuation;
		//specular_contrib += NOT IMPLEMENTED YET
```

Mais de la m√™me mani√®re que l'on se traine des tableau pour notre unique lumi√®re, on va d√©clarer une variable `specular_contrib` pour pr√©parer l'avenir.

Par ailleurs, vous pouvez remarquer que le facteur d'attenuation est bien calcul√© par application de l'inverse square law :

```glsl
		vec3 light_vec = plight_position[i] - frag_position;
		float d2 = length(light_vec);
		d2 = pow(d2, 2.0);
		float attenuation = 1.0 / d2;
```

Ce qui nous donne le resultat suivant :

{{< rawhtml >}} 

<video width="100%" controls muted loop playsinline autoplay>
    <source src="videos/distance_only_light.mp4" type="video/mp4">
    Your browser does not support the video tag.  
</video>

{{< /rawhtml >}}

## IV. Conclusion
Comme on a pu le voire en image, ce modele d'illumination marche tr√®s bien dans "Days of the Porcupine", mais il faut avouer que sur notre sc√®ne il est un peu fade. Le rendu est tr√®s plat et avec des couleurs pleines comme celles-ci, on a du mal √† distinguer le relief. 

Bien entandu nous am√©liorerons √ßa dans la Part II en iml√©mentant un nouveau mod√®le un peu plus proche de notre objectif final. Nous ajouteront √©galement de la lumi√®re d√©terministe pr√©alablement rendue par Blender.

Maintenant que j'y pense, j'avais dis dans le pr√©c√©dent devlog que nous avions besoin des normales pour impl√©menter la lumi√®re. Mais √©tant donn√© que nous avons ignor√© l'orientation des surfaces, on en a finalement pas eu besoin. C'est domage, √ßa veut dire qu'on aurait pu traiter le sujet un poil plus t√¥t dans la s√©rie. 

A ma d√©charge, je n'avais pas pr√©vu de couper ce num√©ro ici. La preuve que m√™me en √©crivant depuis le futur, on peut quand m√™me arriver √† se planter üòÖ.
